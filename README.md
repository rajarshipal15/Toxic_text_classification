# Toxic_text_classification
 We have performed text classification on the Kaggle Toxic Comments Challenge data. We have used Glove word embeddings and Bi-LSTM for our model. After 5 epochs of training we obtained a validation AUC of 0.984.   
