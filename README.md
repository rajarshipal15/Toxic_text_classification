# Toxic_text_classification
 Here I  have performed text classification on the Kaggle Toxic Comments Challenge data. After EDA and data cleaning, I  used Glove word embeddings and a Bi-LSTM followed by a fully connected layer for the model. After 5 epochs of training I obtained a validation AUC of 0.984.   
