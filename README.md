# Toxic_text_classification
Here we perform text classification on the Kaggle Toxic Comments Challenge data. We have used Glove word embeddings and Bi-LSTM for our model. After 5 epochs of training we obtained a validation AUC of 0.984.   
